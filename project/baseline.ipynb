{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Setting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0-1. Library 설치"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: datasets in /home/ho/.local/lib/python3.8/site-packages (from -r requirement.txt (line 1)) (2.18.0)\n",
      "Collecting jsonlines\n",
      "  Using cached jsonlines-4.0.0-py3-none-any.whl (8.7 kB)\n",
      "Requirement already satisfied: accelerate in /home/ho/.local/lib/python3.8/site-packages (from -r requirement.txt (line 3)) (0.30.0)\n",
      "Collecting peft\n",
      "  Using cached peft-0.11.1-py3-none-any.whl (251 kB)\n",
      "Requirement already satisfied: bitsandbytes in /home/ho/.local/lib/python3.8/site-packages (from -r requirement.txt (line 5)) (0.42.0)\n",
      "Requirement already satisfied: transformers in /home/ho/.local/lib/python3.8/site-packages (from -r requirement.txt (line 6)) (4.38.1)\n",
      "Requirement already satisfied: trl in /home/ho/.local/lib/python3.8/site-packages (from -r requirement.txt (line 7)) (0.8.6)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/lib/python3/dist-packages (from datasets->-r requirement.txt (line 1)) (5.3.1)\n",
      "Requirement already satisfied: pyarrow-hotfix in /home/ho/.local/lib/python3.8/site-packages (from datasets->-r requirement.txt (line 1)) (0.6)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /home/ho/.local/lib/python3.8/site-packages (from datasets->-r requirement.txt (line 1)) (0.3.8)\n",
      "Requirement already satisfied: numpy>=1.17 in /home/ho/.local/lib/python3.8/site-packages (from datasets->-r requirement.txt (line 1)) (1.23.5)\n",
      "Requirement already satisfied: multiprocess in /home/ho/.local/lib/python3.8/site-packages (from datasets->-r requirement.txt (line 1)) (0.70.16)\n",
      "Requirement already satisfied: aiohttp in /home/ho/.local/lib/python3.8/site-packages (from datasets->-r requirement.txt (line 1)) (3.9.3)\n",
      "Requirement already satisfied: pandas in /home/ho/.local/lib/python3.8/site-packages (from datasets->-r requirement.txt (line 1)) (2.0.3)\n",
      "Requirement already satisfied: fsspec[http]<=2024.2.0,>=2023.1.0 in /home/ho/.local/lib/python3.8/site-packages (from datasets->-r requirement.txt (line 1)) (2023.10.0)\n",
      "Requirement already satisfied: xxhash in /home/ho/.local/lib/python3.8/site-packages (from datasets->-r requirement.txt (line 1)) (3.4.1)\n",
      "Requirement already satisfied: filelock in /home/ho/.local/lib/python3.8/site-packages (from datasets->-r requirement.txt (line 1)) (3.13.1)\n",
      "Requirement already satisfied: tqdm>=4.62.1 in /home/ho/.local/lib/python3.8/site-packages (from datasets->-r requirement.txt (line 1)) (4.66.1)\n",
      "Requirement already satisfied: pyarrow>=12.0.0 in /home/ho/.local/lib/python3.8/site-packages (from datasets->-r requirement.txt (line 1)) (15.0.2)\n",
      "Requirement already satisfied: requests>=2.19.0 in /home/ho/.local/lib/python3.8/site-packages (from datasets->-r requirement.txt (line 1)) (2.31.0)\n",
      "Requirement already satisfied: packaging in /home/ho/.local/lib/python3.8/site-packages (from datasets->-r requirement.txt (line 1)) (23.2)\n",
      "Requirement already satisfied: huggingface-hub>=0.19.4 in /home/ho/.local/lib/python3.8/site-packages (from datasets->-r requirement.txt (line 1)) (0.20.3)\n",
      "Requirement already satisfied: attrs>=19.2.0 in /home/ho/.local/lib/python3.8/site-packages (from jsonlines->-r requirement.txt (line 2)) (23.1.0)\n",
      "Requirement already satisfied: safetensors>=0.3.1 in /home/ho/.local/lib/python3.8/site-packages (from accelerate->-r requirement.txt (line 3)) (0.4.2)\n",
      "Requirement already satisfied: torch>=1.10.0 in /home/ho/.local/lib/python3.8/site-packages (from accelerate->-r requirement.txt (line 3)) (2.1.0)\n",
      "Requirement already satisfied: psutil in /home/ho/.local/lib/python3.8/site-packages (from accelerate->-r requirement.txt (line 3)) (5.9.6)\n",
      "Requirement already satisfied: scipy in /home/ho/.local/lib/python3.8/site-packages (from bitsandbytes->-r requirement.txt (line 5)) (1.10.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /home/ho/.local/lib/python3.8/site-packages (from transformers->-r requirement.txt (line 6)) (2023.12.25)\n",
      "Requirement already satisfied: tokenizers<0.19,>=0.14 in /home/ho/.local/lib/python3.8/site-packages (from transformers->-r requirement.txt (line 6)) (0.15.2)\n",
      "Requirement already satisfied: tyro>=0.5.11 in /home/ho/.local/lib/python3.8/site-packages (from trl->-r requirement.txt (line 7)) (0.8.4)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /home/ho/.local/lib/python3.8/site-packages (from aiohttp->datasets->-r requirement.txt (line 1)) (1.3.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /home/ho/.local/lib/python3.8/site-packages (from aiohttp->datasets->-r requirement.txt (line 1)) (1.9.4)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0; python_version < \"3.11\" in /home/ho/.local/lib/python3.8/site-packages (from aiohttp->datasets->-r requirement.txt (line 1)) (4.0.3)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /home/ho/.local/lib/python3.8/site-packages (from aiohttp->datasets->-r requirement.txt (line 1)) (1.4.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /home/ho/.local/lib/python3.8/site-packages (from aiohttp->datasets->-r requirement.txt (line 1)) (6.0.5)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /home/ho/.local/lib/python3.8/site-packages (from pandas->datasets->-r requirement.txt (line 1)) (2023.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /home/ho/.local/lib/python3.8/site-packages (from pandas->datasets->-r requirement.txt (line 1)) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/ho/.local/lib/python3.8/site-packages (from pandas->datasets->-r requirement.txt (line 1)) (2023.3.post1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/lib/python3/dist-packages (from requests>=2.19.0->datasets->-r requirement.txt (line 1)) (2019.11.28)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/lib/python3/dist-packages (from requests>=2.19.0->datasets->-r requirement.txt (line 1)) (2.8)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/ho/.local/lib/python3.8/site-packages (from requests>=2.19.0->datasets->-r requirement.txt (line 1)) (3.3.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/lib/python3/dist-packages (from requests>=2.19.0->datasets->-r requirement.txt (line 1)) (1.25.8)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /home/ho/.local/lib/python3.8/site-packages (from huggingface-hub>=0.19.4->datasets->-r requirement.txt (line 1)) (4.8.0)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54; platform_system == \"Linux\" and platform_machine == \"x86_64\" in /home/ho/.local/lib/python3.8/site-packages (from torch>=1.10.0->accelerate->-r requirement.txt (line 3)) (11.0.2.54)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105; platform_system == \"Linux\" and platform_machine == \"x86_64\" in /home/ho/.local/lib/python3.8/site-packages (from torch>=1.10.0->accelerate->-r requirement.txt (line 3)) (12.1.105)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105; platform_system == \"Linux\" and platform_machine == \"x86_64\" in /home/ho/.local/lib/python3.8/site-packages (from torch>=1.10.0->accelerate->-r requirement.txt (line 3)) (12.1.105)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106; platform_system == \"Linux\" and platform_machine == \"x86_64\" in /home/ho/.local/lib/python3.8/site-packages (from torch>=1.10.0->accelerate->-r requirement.txt (line 3)) (10.3.2.106)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.18.1; platform_system == \"Linux\" and platform_machine == \"x86_64\" in /home/ho/.local/lib/python3.8/site-packages (from torch>=1.10.0->accelerate->-r requirement.txt (line 3)) (2.18.1)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26; platform_system == \"Linux\" and platform_machine == \"x86_64\" in /home/ho/.local/lib/python3.8/site-packages (from torch>=1.10.0->accelerate->-r requirement.txt (line 3)) (8.9.2.26)\n",
      "Requirement already satisfied: sympy in /home/ho/.local/lib/python3.8/site-packages (from torch>=1.10.0->accelerate->-r requirement.txt (line 3)) (1.12)\n",
      "Requirement already satisfied: networkx in /home/ho/.local/lib/python3.8/site-packages (from torch>=1.10.0->accelerate->-r requirement.txt (line 3)) (3.1)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105; platform_system == \"Linux\" and platform_machine == \"x86_64\" in /home/ho/.local/lib/python3.8/site-packages (from torch>=1.10.0->accelerate->-r requirement.txt (line 3)) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107; platform_system == \"Linux\" and platform_machine == \"x86_64\" in /home/ho/.local/lib/python3.8/site-packages (from torch>=1.10.0->accelerate->-r requirement.txt (line 3)) (11.4.5.107)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1; platform_system == \"Linux\" and platform_machine == \"x86_64\" in /home/ho/.local/lib/python3.8/site-packages (from torch>=1.10.0->accelerate->-r requirement.txt (line 3)) (12.1.3.1)\n",
      "Requirement already satisfied: jinja2 in /home/ho/.local/lib/python3.8/site-packages (from torch>=1.10.0->accelerate->-r requirement.txt (line 3)) (3.1.2)\n",
      "Requirement already satisfied: triton==2.1.0; platform_system == \"Linux\" and platform_machine == \"x86_64\" in /home/ho/.local/lib/python3.8/site-packages (from torch>=1.10.0->accelerate->-r requirement.txt (line 3)) (2.1.0)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106; platform_system == \"Linux\" and platform_machine == \"x86_64\" in /home/ho/.local/lib/python3.8/site-packages (from torch>=1.10.0->accelerate->-r requirement.txt (line 3)) (12.1.0.106)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105; platform_system == \"Linux\" and platform_machine == \"x86_64\" in /home/ho/.local/lib/python3.8/site-packages (from torch>=1.10.0->accelerate->-r requirement.txt (line 3)) (12.1.105)\n",
      "Requirement already satisfied: rich>=11.1.0 in /home/ho/.local/lib/python3.8/site-packages (from tyro>=0.5.11->trl->-r requirement.txt (line 7)) (13.7.1)\n",
      "Requirement already satisfied: eval-type-backport>=0.1.3; python_version < \"3.10\" in /home/ho/.local/lib/python3.8/site-packages (from tyro>=0.5.11->trl->-r requirement.txt (line 7)) (0.2.0)\n",
      "Requirement already satisfied: shtab>=1.5.6 in /home/ho/.local/lib/python3.8/site-packages (from tyro>=0.5.11->trl->-r requirement.txt (line 7)) (1.7.1)\n",
      "Requirement already satisfied: docstring-parser>=0.14.1 in /home/ho/.local/lib/python3.8/site-packages (from tyro>=0.5.11->trl->-r requirement.txt (line 7)) (0.16)\n",
      "Requirement already satisfied: six>=1.5 in /usr/lib/python3/dist-packages (from python-dateutil>=2.8.2->pandas->datasets->-r requirement.txt (line 1)) (1.14.0)\n",
      "Requirement already satisfied: mpmath>=0.19 in /home/ho/.local/lib/python3.8/site-packages (from sympy->torch>=1.10.0->accelerate->-r requirement.txt (line 3)) (1.3.0)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in /home/ho/.local/lib/python3.8/site-packages (from nvidia-cusolver-cu12==11.4.5.107; platform_system == \"Linux\" and platform_machine == \"x86_64\"->torch>=1.10.0->accelerate->-r requirement.txt (line 3)) (12.3.52)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/ho/.local/lib/python3.8/site-packages (from jinja2->torch>=1.10.0->accelerate->-r requirement.txt (line 3)) (2.1.3)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /home/ho/.local/lib/python3.8/site-packages (from rich>=11.1.0->tyro>=0.5.11->trl->-r requirement.txt (line 7)) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /home/ho/.local/lib/python3.8/site-packages (from rich>=11.1.0->tyro>=0.5.11->trl->-r requirement.txt (line 7)) (2.16.1)\n",
      "Requirement already satisfied: mdurl~=0.1 in /home/ho/.local/lib/python3.8/site-packages (from markdown-it-py>=2.2.0->rich>=11.1.0->tyro>=0.5.11->trl->-r requirement.txt (line 7)) (0.1.2)\n",
      "Installing collected packages: jsonlines, peft\n",
      "Successfully installed jsonlines-4.0.0 peft-0.11.1\n"
     ]
    }
   ],
   "source": [
    "!pip3 install -r requirement.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0-2. Hugging Face 로그인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token will not been saved to git credential helper. Pass `add_to_git_credential=True` if you want to set the git credential as well.\n",
      "Token is valid (permission: fineGrained).\n",
      "Your token has been saved to /home/ho/.cache/huggingface/token\n",
      "Login successful\n"
     ]
    }
   ],
   "source": [
    "import huggingface_hub\n",
    "\n",
    "token = \"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\"\n",
    "huggingface_hub.login(token)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Prepare the Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1-1. 학습 데이터셋 구성 (jsonl 파일로 만들기)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "def make_jsonl(input_paths, label_paths, jsonl_path):\n",
    "    assert len(input_paths) == len(label_paths)\n",
    "\n",
    "    data = []\n",
    "    for input_path, label_path in zip(input_paths, label_paths):\n",
    "        with open(input_path, 'r', encoding='utf-8') as f:\n",
    "            inputs = [line.strip() for line in f]\n",
    "        \n",
    "        with open(label_path, 'r', encoding='utf-8') as f:\n",
    "            labels = [line.strip() for line in f]\n",
    "\n",
    "        assert len(inputs) == len(labels)\n",
    "\n",
    "        for input, label in zip(inputs, labels):\n",
    "            data.append({'input': input, 'label': label})\n",
    "\n",
    "    with open(jsonl_path, 'w', encoding='utf-8') as f:\n",
    "        for d in data:\n",
    "            f.write(json.dumps(d, ensure_ascii=False) + '\\n')\n",
    "\n",
    "root = \"./dataset\"\n",
    "index = [\"00\", \"01\", \"02\"]\n",
    "\n",
    "input_paths = [os.path.join(root, f\"output_text_{idx}.txt\") for idx in index]\n",
    "label_paths = [os.path.join(root, f\"input_text_{idx}.txt\") for idx in index]\n",
    "jsonl_path = os.path.join(root, \"train_data.jsonl\")\n",
    "\n",
    "make_jsonl(input_paths, label_paths, jsonl_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1-2. Fine-tuning 포맷으로 변환"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset({\n",
      "    features: ['text'],\n",
      "    num_rows: 6612\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "import jsonlines\n",
    "import datasets\n",
    "\n",
    "def make_dataset(jsonl_path):\n",
    "    dataset = []\n",
    "    system = \"A chat between a curious user and an artificial intelligence assistant. The assistant gives helpful, detailed, and polite answers to the user's questions.\"\n",
    "\n",
    "    with jsonlines.open(jsonl_path) as f:\n",
    "        for line in f.iter():\n",
    "            formatted = f\"{system}\\nHuman: {line['input']}\\nAssistant: {line['label']}\"\n",
    "            dataset.append(formatted)\n",
    "    \n",
    "    dataset = datasets.Dataset.from_dict({\"text\": dataset})\n",
    "    return dataset\n",
    "\n",
    "dataset = make_dataset(jsonl_path)\n",
    "print(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "참고) Hugging Face에 업로드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ef2df8bc222a4f768e273042a1921499",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Uploading the dataset shards:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fec84dd938df4f86985a17ad53a943ab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating parquet from Arrow format:   0%|          | 0/7 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d8a508e772a24e629f4e6a31f23486a4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md:   0%|          | 0.00/271 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "CommitInfo(commit_url='https://huggingface.co/datasets/kanghokh/ocr_data/commit/8c21dc77efcd60d1a9fb52df20f101ee56f62508', commit_message='Upload dataset', commit_description='', oid='8c21dc77efcd60d1a9fb52df20f101ee56f62508', pr_url=None, pr_revision=None, pr_num=None)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.push_to_hub(\"kanghokh/ocr_data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Fine-tuning LLM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2-1. 모델 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model = \"yanolja/EEVE-Korean-Instruct-10.8B-v1.0\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2-2. Dataset 설정"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "참고) HuggingFace로부터 Dataset 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset({\n",
      "    features: ['text'],\n",
      "    num_rows: 6612\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "ocr_data = \"kanghokh/ocr_data\"\n",
    "dataset = load_dataset(ocr_data, split=\"train\")\n",
    "print(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2-3. QLoRA Fine-tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import BitsAndBytesConfig\n",
    "\n",
    "compute_dtype = getattr(torch, \"float16\")\n",
    "qlora_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_quant_type=\"nf4\",\n",
    "    bnb_4bit_compute_dtype=compute_dtype,\n",
    "    bnb_4bit_use_double_quant=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2-4. Model  불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1427a0bcdd024a63a5781eee935468a5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/704 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`low_cpu_mem_usage` was None, now set to True since model is quantized.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "83705a6c99e9437ea764b7466d360b2e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors.index.json:   0%|          | 0.00/35.8k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c12777c588a34105a6f3424883cf6f69",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading shards:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fd3071529d604955ae38467c1214e33a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00001-of-00005.safetensors:   0%|          | 0.00/4.90G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b99ec53f549a4224a236811aaf61c068",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00002-of-00005.safetensors:   0%|          | 0.00/4.92G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "088f6c5be0754c938e9ca35ce3d1c6ef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00003-of-00005.safetensors:   0%|          | 0.00/5.00G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "df93685717c4465ba75852a9783d8011",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00004-of-00005.safetensors:   0%|          | 0.00/4.92G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ea1affd949d74bc8b895761ab6ff162c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00005-of-00005.safetensors:   0%|          | 0.00/1.88G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ab918bd18b4341a4b8ce94218b529acc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f036caccc56d4b359e6725ea4bc596a6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/1.86k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b2b1c193937c4810b9429f2f970d164a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/2.18M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "58d4ce58ec0046dbaa764170a7f6703c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/557 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LlamaForCausalLM(\n",
      "  (model): LlamaModel(\n",
      "    (embed_tokens): Embedding(40960, 4096)\n",
      "    (layers): ModuleList(\n",
      "      (0-47): 48 x LlamaDecoderLayer(\n",
      "        (self_attn): LlamaAttention(\n",
      "          (q_proj): Linear4bit(in_features=4096, out_features=4096, bias=False)\n",
      "          (k_proj): Linear4bit(in_features=4096, out_features=1024, bias=False)\n",
      "          (v_proj): Linear4bit(in_features=4096, out_features=1024, bias=False)\n",
      "          (o_proj): Linear4bit(in_features=4096, out_features=4096, bias=False)\n",
      "          (rotary_emb): LlamaRotaryEmbedding()\n",
      "        )\n",
      "        (mlp): LlamaMLP(\n",
      "          (gate_proj): Linear4bit(in_features=4096, out_features=14336, bias=False)\n",
      "          (up_proj): Linear4bit(in_features=4096, out_features=14336, bias=False)\n",
      "          (down_proj): Linear4bit(in_features=14336, out_features=4096, bias=False)\n",
      "          (act_fn): SiLU()\n",
      "        )\n",
      "        (input_layernorm): LlamaRMSNorm()\n",
      "        (post_attention_layernorm): LlamaRMSNorm()\n",
      "      )\n",
      "    )\n",
      "    (norm): LlamaRMSNorm()\n",
      "  )\n",
      "  (lm_head): Linear(in_features=4096, out_features=40960, bias=False)\n",
      ")\n",
      "LlamaTokenizerFast(name_or_path='yanolja/EEVE-Korean-Instruct-10.8B-v1.0', vocab_size=40960, model_max_length=1000000000000000019884624838656, is_fast=True, padding_side='left', truncation_side='right', special_tokens={'bos_token': '<s>', 'eos_token': '<|im_end|>', 'unk_token': '<unk>', 'pad_token': '</s>'}, clean_up_tokenization_spaces=False),  added_tokens_decoder={\n",
      "\t0: AddedToken(\"<unk>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t1: AddedToken(\"<s>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t2: AddedToken(\"</s>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t32000: AddedToken(\"<|im_end|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    base_model,\n",
    "    quantization_config=qlora_config,\n",
    "    trust_remote_code=True\n",
    ")\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\n",
    "    base_model,\n",
    "    trust_remote_code=True\n",
    ")\n",
    "\n",
    "print(model)\n",
    "print(tokenizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2-5. PEFT Parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "from peft import LoraConfig\n",
    "\n",
    "peft_param = LoraConfig(\n",
    "    lora_alpha=16,\n",
    "    lora_dropout=0.1,\n",
    "    r=64,\n",
    "    bias=\"none\",\n",
    "    task_type=\"CASUAL_LM\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2-6. Training Parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TrainingArguments\n",
    "\n",
    "training_params = TrainingArguments(\n",
    "    output_dir=\"./results\",\n",
    "    num_train_epochs=5,\n",
    "    per_device_train_batch_size=4,\n",
    "    gradient_accumulation_steps=1,\n",
    "    optim=\"paged_adamw_32bit\",\n",
    "    save_steps=25,\n",
    "    logging_steps=25,\n",
    "    learning_rate=2e-4,\n",
    "    weight_decay=0.001,\n",
    "    fp16=False,\n",
    "    bf16=False,\n",
    "    max_grad_norm=0.3,\n",
    "    max_steps=-1,\n",
    "    warmup_ratio=0.03,\n",
    "    group_by_length=True,\n",
    "    lr_scheduler_type=\"constant\",\n",
    "    report_to=\"tensorboard\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2-7. Supervised Fine-tuning (SFT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from transformers import TrainingArguments\n",
    "\n",
    "trainer = SFTTrainer(\n",
    "    model=model,\n",
    "    train_dataset=dataset,\n",
    "    peft_config=peft_params,\n",
    "    dataset_text_field=\"text\",\n",
    "    max_seq_length=None,\n",
    "    tokenizer=tokenizer,\n",
    "    args=training_params,\n",
    "    packing=False,\n",
    ")\n",
    "\n",
    "os.makedirs(\"./results/\", exist_ok=True)\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorboard import notebook\n",
    "\n",
    "log_dir = \"results/runs\"\n",
    "notebook.start(\"--logdir {} --port 4000\".format(log_dir))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3-1. 텍스트 생성을 위한 Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "generator = pipeline(task=\"text-generation\", model=model, tokenizer=tokenizer)\n",
    "\n",
    "key = \"나는 오는 학교를 갓다,\"\n",
    "template = f\"\"\"{system}\\nHuman: {key}\\nAssistant:\\n\"\"\"\n",
    "\n",
    "response = generator(template, max_length=200, do_sample=True, pad_token_id=tokenizer.eos_token_id)\n",
    "print(response[0]['generated_text'].replace(prompt, \"\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3-2. 모델 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_path = f\"./resutls/\"\n",
    "trainer.save_model(save_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
